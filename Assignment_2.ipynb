{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Create Assignment",
    "colab": {
      "name": "Intro ML 2 - Yuval.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXcTGuUgDupM",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6bd0516e7cb654f5",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "source": [
        "# Exercise 2: Decision Trees\n",
        "\n",
        "In this assignment you will implement a Decision Tree algorithm as learned in class.\n",
        "\n",
        "## Read the following instructions carefully:\n",
        "\n",
        "1. This jupyter notebook contains all the step by step instructions needed for this exercise.\n",
        "1. Submission includes this notebook only with the exercise number and your ID as the filename. For example: `hw2_123456789_987654321.ipynb` if you submitted in pairs and `hw2_123456789.ipynb` if you submitted the exercise alone.\n",
        "1. Write **efficient vectorized** code whenever possible. Some calculations in this exercise take several minutes when implemented efficiently, and might take much longer otherwise. Unnecessary loops will result in point deduction.\n",
        "1. You are responsible for the correctness of your code and should add as many tests as you see fit. Tests will not be graded nor checked.\n",
        "1. Write your functions in this notebook only. **Do not create Python modules and import them**.\n",
        "1. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/) and [numpy](https://www.numpy.org/devdocs/reference/) only. **Do not import anything else.**\n",
        "1. Your code must run without errors. Make sure your `numpy` version is at least 1.15.4 and that you are using at least python 3.6. Changes of the configuration we provided are at your own risk. Any code that cannot run will not be graded.\n",
        "1. Write your own code. Cheating will not be tolerated.\n",
        "1. Answers to qualitative questions should be written in **markdown** cells (with $\\LaTeX$ support). Answers that will be written in commented code blocks will not be checked.\n",
        "\n",
        "## In this exercise you will perform the following:\n",
        "1. Practice OOP in python.\n",
        "2. Implement two impurity measures: Gini and Entropy.\n",
        "3. Construct a decision tree algorithm.\n",
        "4. Prune the tree to achieve better results.\n",
        "5. Visualize your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SLjAIN-Dupf"
      },
      "source": [
        "# I have read and understood the instructions: *** 204287635 & 209045749 ***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzwUZY5WDuph",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ed9fe7b1026e33cb",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# make matplotlib figures appear inline in the notebook\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59Q98-YjDupj",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-c6ac605270c2b091",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "source": [
        "## Warmup - OOP in python\n",
        "\n",
        "Our desicion tree will be implemented using a dedicated python class. Python classes are very similar to classes in Java.\n",
        "\n",
        "\n",
        "You can use the following [site](https://jeffknupp.com/blog/2014/06/18/improve-your-python-python-classes-and-object-oriented-programming/) to learn about classes in python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B96rCAEFDupj"
      },
      "source": [
        "class Node(object):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.children = []\n",
        "\n",
        "    def add_child(self, node):\n",
        "        self.children.append(node)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPrNgSKaDupk",
        "outputId": "a3196978-5b68-4a98-a6d3-04d47fbdabed"
      },
      "source": [
        "n = Node(5)\n",
        "p = Node(6)\n",
        "q = Node(7)\n",
        "n.add_child(p)\n",
        "n.add_child(q)\n",
        "n.children"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<__main__.Node at 0x1c62454cbb0>, <__main__.Node at 0x1c62454cb50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMVbSL9ADupm",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2f1ceb251c649b62",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "For the following exercise, we will use a dataset containing mushroom data `agaricus-lepiota.csv`. \n",
        "\n",
        "This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family. Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous\n",
        "one (=there are only two classes **edible** and **poisonous**). \n",
        "    \n",
        "The dataset contains 8124 observations with 22 features:\n",
        "1. cap-shape: bell=b,conical=c,convex=x,flat=f,knobbed=k,sunken=s\n",
        "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
        "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
        "4. bruises: bruises=t,no=f\n",
        "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
        "6. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
        "7. gill-spacing: close=c,crowded=w,distant=d\n",
        "8. gill-size: broad=b,narrow=n\n",
        "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g,green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
        "10. stalk-shape: enlarging=e,tapering=t\n",
        "11. stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r\n",
        "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
        "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
        "16. veil-type: partial=p,universal=u\n",
        "17. veil-color: brown=n,orange=o,white=w,yellow=y\n",
        "18. ring-number: none=n,one=o,two=t\n",
        "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
        "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
        "21. population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
        "22. habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d\n",
        "\n",
        "First, we will read and explore the data using pandas and the `.read_csv` method. Pandas is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9KXpRX2Dupo",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d79cb4542926ad3f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "source": [
        "# load dataset\n",
        "data = pd.read_csv('agaricus-lepiota.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtivfaAaDupp"
      },
      "source": [
        "One of the advantages of the Decision Tree algorithm is that almost no preprocessing is required. However, finding missing values is always required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAtpeaZaDupq"
      },
      "source": [
        "#############################################################################\n",
        "# TODO: Find the columns with missing values and remove them from the data.#\n",
        "#############################################################################\n",
        "data_columns = data.columns.values.tolist()\n",
        "columns_to_remove = []\n",
        "for col in data_columns:\n",
        "    if (data[col].dropna().empty):\n",
        "        columns_to_remove.append(col)\n",
        "data = data.drop(columns = columns_to_remove)\n",
        "pass\n",
        "#############################################################################\n",
        "#                             END OF YOUR CODE                              #\n",
        "#############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyNJKtFyDups"
      },
      "source": [
        "We will split the dataset to `Training` and `Testing` datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPaAd6daDupt",
        "outputId": "56190090-cc30-4b73-9fb1-66b4c9b638eb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Making sure the last column will hold the labels\n",
        "X, y = data.drop('class', axis=1), data['class']\n",
        "X = np.column_stack([X,y])\n",
        "# split dataset using random_state to get the same split each time\n",
        "X_train, X_test = train_test_split(X, random_state=99)\n",
        "\n",
        "print(\"Training dataset shape: \", X_train.shape)\n",
        "print(\"Testing dataset shape: \", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset shape:  (6093, 22)\n",
            "Testing dataset shape:  (2031, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS-oYnWWDupu",
        "outputId": "5727212f-bf85-4dc9-a3cd-e01ac9bf92e9"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8124,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUQMbBVHDupv",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-fd7b0191f3f1e897",
          "locked": true,
          "schema_version": 1,
          "solution": false
        }
      },
      "source": [
        "## Impurity Measures\n",
        "\n",
        "Impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. Implement the functions `calc_gini` and `calc_entropy`. You are encouraged to test your implementation (10 points)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAHuwA0FDupv"
      },
      "source": [
        "def calc_gini(data):\n",
        "    \"\"\"\n",
        "    Calculate gini impurity measure of a dataset.\n",
        " \n",
        "    Input:\n",
        "    - data: any dataset where the last column holds the labels.\n",
        " \n",
        "    Returns the gini impurity.    \n",
        "    \"\"\"\n",
        "    gini = 0.0\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    labels = np.unique(data[:, -1])\n",
        "    gini = 1.0\n",
        "    for label in labels:\n",
        "        gini -= (np.count_nonzero(data[:, -1] == label) / data.shape[0]) ** 2\n",
        "    pass\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKj2-O_3Dupw"
      },
      "source": [
        "def calc_entropy(data):\n",
        "    \"\"\"\n",
        "    Calculate the entropy of a dataset.\n",
        "\n",
        "    Input:\n",
        "    - data: any dataset where the last column holds the labels.\n",
        "\n",
        "    Returns the entropy of the dataset.    \n",
        "    \"\"\"\n",
        "    entropy = 0.0\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    labels = np.unique(data[:, -1])\n",
        "    for label in labels:\n",
        "        entropy -= (np.count_nonzero(data[:, -1] == label) / data.shape[0]) * np.log2(np.count_nonzero(data[:, -1] == label) / data.shape[0])\n",
        "    pass\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rvpV2knDupw",
        "scrolled": true,
        "outputId": "7992bf49-5c4c-40fc-d243-f1c6a192195b"
      },
      "source": [
        "##### Your Tests Here #####\n",
        "calc_gini(X), calc_entropy(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.49956363223797745, 0.9993703627906085)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23yvbpAWDupx"
      },
      "source": [
        "## Goodness of Split\n",
        "\n",
        "Given a feature the Goodnees of Split measures the reduction in the impurity if we split the data according to the feature.\n",
        "$$\n",
        "\\Delta\\varphi(S, A) = \\varphi(S) - \\sum_{v\\in Values(A)} \\frac{|S_v|}{|S|}\\varphi(S_v)\n",
        "$$\n",
        "\n",
        "In our implementation the goodness_of_split function will return either the Goodness of Split or the Gain Ratio as learned in class. You'll control the return value with the `gain_ratio` parameter. If this parameter will set to False (the default value) it will return the regular Goodness of Split. If it will set to True it will return the Gain Ratio.\n",
        "$$\n",
        "GainRatio(S,A)=\\frac{InformationGain(S,A)}{SplitInformation(S,A)}\n",
        "$$\n",
        "Where:\n",
        "$$\n",
        "InformationGain(S,A)=Goodness\\ of\\ Split\\ calculated\\ with\\ Entropy\\ as\\ the\\ Impurity\\ function \\\\\n",
        "SplitInformation(S,A)=- \\sum_{a\\in A} \\frac{|S_a|}{|S|}\\log\\frac{|S_a|}{|S|}\n",
        "$$\n",
        "NOTE: you can add more parameters to the function and you can also add more returning variables (The given parameters and the given returning variable should not be touch). (10 Points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt7XjAg1Dupx"
      },
      "source": [
        "def goodness_of_split(data, feature, impurity_func, gain_ratio=False):\n",
        "    \"\"\"\n",
        "    Calculate the goodness of split of a dataset given a feature and impurity function.\n",
        "\n",
        "    Input:\n",
        "    - data: any dataset where the last column holds the labels.\n",
        "    - feature: the feature index.\n",
        "    - impurity func: a function that calculates the impurity.\n",
        "    - gain_ratio: goodness of split or gain ratio flag.\n",
        "\n",
        "    Returns the goodness of split (or the Gain Ration).  \n",
        "    \"\"\"\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    values = np.unique(data[:, feature])\n",
        "    if (gain_ratio == True):\n",
        "        impurity_func = calc_entropy\n",
        "    goodness = impurity_func(data)\n",
        "    for value in values:\n",
        "        sub_data = []\n",
        "        for row in data:\n",
        "            if (row[feature] == value):\n",
        "                sub_data.append(row)\n",
        "        goodness -= ((np.count_nonzero(data[:, feature] == value) / data.shape[0]) * impurity_func(np.array(sub_data)))\n",
        "    if (gain_ratio == True):\n",
        "        split_info = 0.0\n",
        "        for value in values:\n",
        "            split_info -= ((np.count_nonzero(data[:, feature] == value) / data.shape[0]) * np.log2(np.count_nonzero(data[:, feature] == value) / data.shape[0]))\n",
        "        return (goodness / split_info)\n",
        "    pass\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return goodness    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef56EkDMDupy"
      },
      "source": [
        "## Building a Decision Tree\n",
        "\n",
        "Use a Python class to construct the decision tree. Your class should support the following functionality:\n",
        "\n",
        "1. Initiating a node for a decision tree. You will need to use several class methods and class attributes and you are free to use them as you see fit. We recommend that every node will hold the feature and value used for the split and its children.\n",
        "2. Your code should support both Gini and Entropy as impurity measures. \n",
        "3. The provided data includes categorical data. In this exercise, when splitting a node create the number of children needed according to the attribute unique values.\n",
        "\n",
        "Complete the class `DecisionNode`. The structure of this class is entirely up to you. \n",
        "\n",
        "Complete the function `build_tree`. This function should get the training dataset and the impurity as inputs, initiate a root for the decision tree and construct the tree according to the procedure you learned in class. (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g14EP-cDupy"
      },
      "source": [
        "class DecisionNode:\n",
        "    \"\"\"\n",
        "    This class will hold everything you require to construct a decision tree.\n",
        "    The structure of this class is up to you. However, you need to support basic \n",
        "    functionality as described above. It is highly recommended that you \n",
        "    first read and understand the entire exercise before diving into this class.\n",
        "    \"\"\"\n",
        "    def __init__(self, feature, pred = None):\n",
        "        self.feature = feature # column index of criteria being tested\n",
        "        self.children = [] # list of children\n",
        "        self.pred = pred # prediction of label\n",
        "        self.features_values = {} # dictionary of all parents feature indexes and values\n",
        "        self.labels_counts = [] # Relevant only for leaves\n",
        "        \n",
        "    def add_child(self, node, feature_value):\n",
        "        feature_values_so_far = self.features_values.copy()\n",
        "        feature_values_so_far[self.feature] = feature_value\n",
        "        node.features_values = feature_values_so_far\n",
        "        self.children.append((node, feature_value))\n",
        "        \n",
        "    def add_label_count(self, label, count):\n",
        "        self.labels_counts.append((label, count))\n",
        "        \n",
        "    def is_leaf(self):\n",
        "        if(len(self.children) == 0):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    \n",
        "    def tree_depth(self):\n",
        "        depth = 0\n",
        "        if self == None:\n",
        "            return 0\n",
        "        else:\n",
        "            for child in self.children:\n",
        "                child_depth = child[0].tree_depth()\n",
        "                if(child_depth > depth):\n",
        "                    depth = child_depth\n",
        "        return depth + 1\n",
        "    \n",
        "    def children_count(self):\n",
        "        return len(self.children)\n",
        "    \n",
        "    def set_pred(self, data):\n",
        "        sub_data = []\n",
        "        for row in data:\n",
        "            flag = True\n",
        "            for feature in self.features_values.keys():\n",
        "                if (row[feature] != self.features_values[feature]):\n",
        "                    flag = False\n",
        "                    break\n",
        "            if (flag == True):\n",
        "                sub_data.append(row)\n",
        "        classes, counts = np.unique((np.array(sub_data))[:, -1], return_counts = True)\n",
        "        maxcount = np.argmax(counts)\n",
        "        maxclass = classes[maxcount]\n",
        "        self.pred = maxclass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNAyswn3Dupz"
      },
      "source": [
        "def build_tree(data, impurity, gain_ratio=False, chi=1, max_depth=1000):\n",
        "    \"\"\"\n",
        "    Build a tree using the given impurity measure and training dataset. \n",
        "    You are required to fully grow the tree until all leaves are pure. \n",
        "\n",
        "    Input:\n",
        "    - data: the training dataset.\n",
        "    - impurity: the chosen impurity measure. Notice that you can send a function\n",
        "                as an argument in python.\n",
        "    - gain_ratio: goodness of split or gain ratio flag\n",
        "    - chi: chi square p-value cut off (1 means no pruning)\n",
        "    - max_depth: the allowable depth of the tree\n",
        "\n",
        "    Output: the root node of the tree.\n",
        "    \"\"\"\n",
        "    root = None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    unused_features = []\n",
        "    for i in range(0, data.shape[1] - 1):\n",
        "        unused_features.append(i)\n",
        "    root = build_tree_recursion(data, impurity, root, 0, unused_features, gain_ratio, chi, chi_table, max_depth)\n",
        "    pass\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return root"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0wKCitJDup0"
      },
      "source": [
        "def build_tree_recursion(data, impurity, root, depth, unused_features, gain_ratio, chi, chi_table, max_depth):\n",
        "    my_unused_features = list(unused_features)\n",
        "    if(depth == max_depth):\n",
        "        return None\n",
        "    \n",
        "    classes, counts = np.unique(data[:, -1], return_counts = True)\n",
        "    \n",
        "    if(classes.shape[0] == 1): # Node is monochromatic, no need to proceed build\n",
        "        root = DecisionNode(None, classes[0])\n",
        "        root.add_label_count(classes[0], counts[0])\n",
        "        return root\n",
        "\n",
        "    if(len(my_unused_features) == 0): # All attributes have been used, Node isn't monochromatic\n",
        "        maxcount = np.argmax(counts)\n",
        "        maxclass = classes[maxcount]\n",
        "        root = DecisionNode(None, maxclass)\n",
        "        for i in range(0, classes.shape[0]):\n",
        "            root.add_label_count(classes[i], counts[i])\n",
        "        return root\n",
        "    \n",
        "    goodness_dict = {}\n",
        "    for feature in my_unused_features: # Find \"best\" question\n",
        "        goodness_dict[feature] = goodness_of_split(data, feature, impurity, gain_ratio)\n",
        "    max_goodness_feature = max(goodness_dict, key = goodness_dict.get)\n",
        "    if(goodness_dict[max_goodness_feature] == 0):  # If all the gains are 0 we need to stop, as mentioned in Piazza\n",
        "        maxcount = np.argmax(counts)\n",
        "        maxclass = classes[maxcount]\n",
        "        root = DecisionNode(None, maxclass)\n",
        "        for i in range(0, classes.shape[0]):\n",
        "            root.add_label_count(classes[i], counts[i])\n",
        "        return root\n",
        "    else:\n",
        "        root = DecisionNode(max_goodness_feature) \n",
        "        values, counts_values = np.unique(data[:, max_goodness_feature], return_counts = True) # Find number of children\n",
        "        \n",
        "        if(chi != 1): # Chi pruning\n",
        "            probs = []\n",
        "            for i in range(0, classes.shape[0]):\n",
        "                probs.append((counts[i] / np.sum(counts))) # Distribution of each class in our node\n",
        "            p, n, E = [], [], []\n",
        "            for value in range(0, values.shape[0]):\n",
        "                p_count = 0\n",
        "                n_count = 0\n",
        "                for instance in range(0, data.shape[0]):\n",
        "                    if(data[instance, max_goodness_feature] == values[value]):\n",
        "                        if(data[instance, -1] == classes[0]):\n",
        "                            p_count = p_count + 1\n",
        "                        if(data[instance, -1] == classes[1]):\n",
        "                            n_count = n_count + 1\n",
        "                p.append(p_count)\n",
        "                n.append(n_count)\n",
        "                current_E = []\n",
        "                for i in range(0, classes.shape[0]):\n",
        "                    current_E.append(counts_values[value] * probs[i])\n",
        "                E.append(current_E)\n",
        "            chi_square = 0.0\n",
        "            for value in range(0, values.shape[0]):\n",
        "                chi_square = chi_square + (((p[value] - E[value][0]) ** 2) / E[value][0]) + (((n[value] - E[value][1]) ** 2) / E[value][1])\n",
        "            if(chi_square < chi_table[values.shape[0] - 1][chi]): # We need to make the node a leaf\n",
        "                maxcount = np.argmax(counts)\n",
        "                maxclass = classes[maxcount]\n",
        "                root.pred = maxclass\n",
        "                for i in range(0, classes.shape[0]):\n",
        "                    root.add_label_count(classes[i], counts[i])\n",
        "                return root\n",
        "        \n",
        "        my_unused_features.remove(max_goodness_feature)\n",
        "        for value in values:\n",
        "            selector = [row for row in range(0, data.shape[0]) if data[row, max_goodness_feature] == value]\n",
        "            child = build_tree_recursion(data[selector, :], impurity, None, depth + 1, my_unused_features, gain_ratio, chi, chi_table, max_depth) # Keep building the tree\n",
        "            if(child != None): # When pruning the tree we interrupt the building, so we need to make the node a leaf\n",
        "                root.add_child(child, value)\n",
        "            else:\n",
        "                maxcount = np.argmax(counts)\n",
        "                maxclass = classes[maxcount]\n",
        "                root.pred = maxclass\n",
        "                root.feature = None\n",
        "                for i in range(0, classes.shape[0]):\n",
        "                    root.add_label_count(classes[i], counts[i])\n",
        "    return root"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnI5XRzVDup2"
      },
      "source": [
        "# python supports passing a function as an argument to another function.\n",
        "tree_gini = build_tree(data = X_train, impurity = calc_gini) # gini and goodness of split\n",
        "tree_entropy = build_tree(data = X_train, impurity = calc_entropy) # entropy and goodness of split\n",
        "tree_entropy_gain_ratio = build_tree(data = X_train, impurity = calc_entropy, gain_ratio = True) # entropy and gain ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oAUf9V4Dup3"
      },
      "source": [
        "## Tree evaluation\n",
        "\n",
        "Complete the functions `predict` and `calc_accuracy`. (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhkD8rThDup4"
      },
      "source": [
        "def predict(node, instance):\n",
        "    \"\"\"\n",
        "    Predict a given instance using the decision tree\n",
        " \n",
        "    Input:\n",
        "    - root: the root of the decision tree.\n",
        "    - instance: an row vector from the dataset. Note that the last element \n",
        "                of this vector is the label of the instance.\n",
        " \n",
        "    Output: the prediction of the instance.\n",
        "    \"\"\"\n",
        "    pred = None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    for child in node.children:\n",
        "        if child[1] == instance[node.feature]:\n",
        "            return predict(child[0], instance)\n",
        "    pass\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return node.pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qyo6mufDup4"
      },
      "source": [
        "def calc_accuracy(node, dataset):\n",
        "    \"\"\"\n",
        "    Predict a given dataset using the decision tree\n",
        " \n",
        "    Input:\n",
        "    - node: a node in the decision tree.\n",
        "    - dataset: the dataset on which the accuracy is evaluated\n",
        " \n",
        "    Output: the accuracy of the decision tree on the given dataset (%).\n",
        "    \"\"\"\n",
        "    accuracy = 0\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    for instance in dataset:\n",
        "        if (predict(node, instance) == instance[-1]):\n",
        "            accuracy += 1\n",
        "    accuracy /= dataset.shape[0]\n",
        "    accuracy *= 100\n",
        "    pass\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WremhoMyDup5"
      },
      "source": [
        "After building the three trees using the training set, you should calculate the accuracy on the test set. For each tree print the training and test accuracy. Select the tree that gave you the best test accuracy. For the rest of the exercise, use that tree (when you asked to build another tree use the same impurity function and same gain_ratio flag). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mK1E0sXDup5",
        "outputId": "807fb626-961b-46c1-e366-d48361eff8ba"
      },
      "source": [
        "#### Your code here ####\n",
        "acc_gini_goodness_train = calc_accuracy(tree_gini, X_train) #gini and goodness of split TrainSet accuracy\n",
        "acc_gini_goodness_test = calc_accuracy(tree_gini, X_test) #gini and goodness of split TestSet accuracy\n",
        "acc_entropy_goodness_train = calc_accuracy(tree_entropy, X_train) #entropy and goodness of split TrainSet accuracy\n",
        "acc_entropy_goodness_test = calc_accuracy(tree_entropy, X_test) #entropy and goodness of split TestSet accuracy\n",
        "acc_entropy_gain_train = calc_accuracy(tree_entropy_gain_ratio, X_train) #entropy and gain ratio TrainSet accuracy\n",
        "acc_entropy_gain_test = calc_accuracy(tree_entropy_gain_ratio, X_test) #entropy and gain ratio TestSet accuracy\n",
        "\n",
        "print(\"gini and goodness of split TrainSet accuracy: \", acc_gini_goodness_train)\n",
        "print(\"gini and goodness of split TestSet accuracy: \", acc_gini_goodness_test)\n",
        "print(\"entropy and goodness of split TrainSet accuracy: \", acc_entropy_goodness_train)\n",
        "print(\"entropy and goodness of split TestSet accuracy: \", acc_entropy_goodness_test)\n",
        "print(\"entropy and gain ratio TrainSet accuracy: \", acc_entropy_gain_train)\n",
        "print(\"entropy and gain ratio TestSet accuracy: \", acc_entropy_gain_test)\n",
        "\n",
        "best_accuracy = acc_gini_goodness_test\n",
        "best_impurity = calc_gini\n",
        "best_gain_ratio = False\n",
        "best_tree = \"gini and goodness of split\"\n",
        "if (acc_entropy_goodness_test > best_accuracy):\n",
        "    best_accuracy = acc_entropy_goodness_test\n",
        "    best_impurity = calc_entropy\n",
        "    best_gain_ratio = False\n",
        "    best_tree = \"entropy and goodness of split\"\n",
        "if (acc_entropy_gain_test > best_accuracy):\n",
        "    best_accuracy = acc_entropy_gain_test\n",
        "    best_impurity = calc_entropy\n",
        "    best_gain_ratio = True\n",
        "    best_tree_description = \"entropy and gain ratio\"\n",
        "\n",
        "print(\"best tree is:\", best_tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gini and goodness of split TrainSet accuracy:  99.24503528639423\n",
            "gini and goodness of split TestSet accuracy:  76.80945347119645\n",
            "entropy and goodness of split TrainSet accuracy:  99.40915805022156\n",
            "entropy and goodness of split TestSet accuracy:  76.31708517971443\n",
            "entropy and gain ratio TrainSet accuracy:  99.63892991957984\n",
            "entropy and gain ratio TestSet accuracy:  75.03692762186115\n",
            "best tree is: gini and goodness of split\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpkxBqSgDup7"
      },
      "source": [
        "## Post pruning\n",
        "\n",
        "Iterate over all nodes in the tree that have at least a single child which is a leaf. For each such node, replace it with its most popular class. Calculate the accuracy on the testing dataset, pick the node that results in the highest testing accuracy and permanently change it in the tree. Repeat this process until you are left with a single node in the tree (the root). Finally, create a plot of the training and testing accuracies as a function of the number of nodes in the tree. (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOcanVXdDup8"
      },
      "source": [
        "#### Your code here ####\n",
        "from copy import copy, deepcopy\n",
        "\n",
        "def post_pruning(root, train, test):\n",
        "    train_acc_array = [calc_accuracy(root, train)]\n",
        "    test_acc_array = [calc_accuracy(root, test)]\n",
        "    nodes = [count_nodes(root)]\n",
        "    best_acc_tree = 0\n",
        "    best_tree = None\n",
        "    curr_acc_tree = 0    \n",
        "    \n",
        "    while(root.children):\n",
        "        \n",
        "        best_acc = -1\n",
        "        best_parent = None\n",
        "        \n",
        "        # an array with all the nodes that have at least one children that is a leaf.\n",
        "        parents = parent_check(root)\n",
        "        \n",
        "        for parent in parents:\n",
        "            # saving the parents children\n",
        "            tmp_childrens = []\n",
        "            for child in parent.children:\n",
        "                tmp_childrens.append(child)\n",
        "    \n",
        "            # making the node to be the the most popular class\n",
        "            parent.set_pred(train)\n",
        "            \n",
        "            # deleting the parents children from the tree\n",
        "            parent.children = []\n",
        "\n",
        "            # calculating the tree accuracy with out the parent            \n",
        "            curr_test_acc = calc_accuracy(root, test)\n",
        "            \n",
        "            # checking if the current split that I deleted was the best one to delete up until now.\n",
        "            if (curr_test_acc > best_acc):\n",
        "                best_acc = curr_test_acc\n",
        "                best_parent = parent \n",
        "                \n",
        "            # returning the childrens value and the parent class.\n",
        "            for child in tmp_childrens:\n",
        "                parent.children.append(child)\n",
        "            parent.pred = None\n",
        "                \n",
        "            nodes_sum = count_nodes(root)\n",
        "\n",
        "        # deletes the nodes that provide the best accuracy and turns their parent to a leaf.\n",
        "        curr_acc_tree = calc_accuracy(root, test)\n",
        "        if curr_acc_tree > best_acc_tree:\n",
        "            best_acc_tree = curr_acc_tree \n",
        "            best_tree = deepcopy(root)\n",
        "            \n",
        "        best_parent.children = []\n",
        "        best_parent.set_pred(train)\n",
        "        \n",
        "        # updating the arrays that need to be returned\n",
        "        nodes.append(nodes_sum)\n",
        "        test_acc_array.append(best_acc)\n",
        "        train_acc = calc_accuracy(root, train)\n",
        "        train_acc_array.append(train_acc)\n",
        "        \n",
        "    return (best_tree ,nodes, train_acc_array, test_acc_array)\n",
        "\n",
        "def count_nodes(node):\n",
        "    if(node.children_count() == 0):\n",
        "        return 1\n",
        "    nodes = 1\n",
        "    for child in node.children:\n",
        "        nodes = nodes + count_nodes(child[0])\n",
        "    return nodes\n",
        "\n",
        "def parent_check(node):\n",
        "    array = []\n",
        "    queue = [node]\n",
        "    \n",
        "    while(len(queue)>0):\n",
        "        curr_node = queue.pop(0)\n",
        "        flag_child = 0\n",
        "        \n",
        "        for child in curr_node.children:\n",
        "            if child[0].children_count() == 0:\n",
        "                if flag_child == 0:\n",
        "                    array.append(curr_node)\n",
        "                    flag_child = 1\n",
        "            else:\n",
        "                queue.append(child[0])        \n",
        "    return array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAox84SGDup9",
        "outputId": "1a449d7c-374d-4074-ff3d-cb35915b8158"
      },
      "source": [
        "train_tree = build_tree(data = X_train, impurity = best_impurity, gain_ratio = best_gain_ratio)\n",
        "best_post_purning_tree, num_of_nodes, training, testing = post_pruning(train_tree, X_train, X_test)\n",
        "\n",
        "plt.plot(num_of_nodes, training, 'r--')\n",
        "plt.plot(num_of_nodes, testing,'b--')\n",
        "\n",
        "plt.xlabel('number of nodes')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('accuracy as a function of the number of nodes')\n",
        "plt.legend(['training data', 'testing data'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0ni-5TPDup-"
      },
      "source": [
        "## Chi square pre-pruning\n",
        "\n",
        "Consider the following p-value cut-off values: [1 (no pruning), 0.5, 0.25, 0.1, 0.05, 0.0001 (max pruning)]. For each value, construct a tree and prune it according to the cut-off value. Next, calculate the training and testing accuracy. On a single plot, draw the training and testing accuracy as a function of the tuple (p-value, tree depth). Mark the best result on the graph with red circle. (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLdw_spXDup-"
      },
      "source": [
        "### Chi square table values ###\n",
        "# The first key is the degree of freedom \n",
        "# The second key is the p-value cut-off\n",
        "# The values are the chi-statistic that you need to use in the pruning\n",
        "chi_table = {1: {0.5 : 0.45,\n",
        "                 0.25 : 1.32,\n",
        "                 0.1 : 2.71,\n",
        "                 0.05 : 3.84,\n",
        "                 0.0001 : 100000},\n",
        "             2: {0.5 : 1.39,\n",
        "                 0.25 : 2.77,\n",
        "                 0.1 : 4.60,\n",
        "                 0.05 : 5.99,\n",
        "                 0.0001 : 100000},\n",
        "             3: {0.5 : 2.37,\n",
        "                 0.25 : 4.11,\n",
        "                 0.1 : 6.25,\n",
        "                 0.05 : 7.82,\n",
        "                 0.0001 : 100000},\n",
        "             4: {0.5 : 3.36,\n",
        "                 0.25 : 5.38,\n",
        "                 0.1 : 7.78,\n",
        "                 0.05 : 9.49,\n",
        "                 0.0001 : 100000},\n",
        "             5: {0.5 : 4.35,\n",
        "                 0.25 : 6.63,\n",
        "                 0.1 : 9.24,\n",
        "                 0.05 : 11.07,\n",
        "                 0.0001 : 100000},\n",
        "             6: {0.5 : 5.35,\n",
        "                 0.25 : 7.84,\n",
        "                 0.1 : 10.64,\n",
        "                 0.05 : 12.59,\n",
        "                 0.0001 : 100000},\n",
        "             7: {0.5 : 6.35,\n",
        "                 0.25 : 9.04,\n",
        "                 0.1 : 12.01,\n",
        "                 0.05 : 14.07,\n",
        "                 0.0001 : 100000},\n",
        "             8: {0.5 : 7.34,\n",
        "                 0.25 : 10.22,\n",
        "                 0.1 : 13.36,\n",
        "                 0.05 : 15.51,\n",
        "                 0.0001 : 100000},\n",
        "             9: {0.5 : 8.34,\n",
        "                 0.25 : 11.39,\n",
        "                 0.1 : 14.68,\n",
        "                 0.05 : 16.92,\n",
        "                 0.0001 : 100000},\n",
        "             10: {0.5 : 9.34,\n",
        "                  0.25 : 12.55,\n",
        "                  0.1 : 15.99,\n",
        "                  0.05 : 18.31,\n",
        "                  0.0001 : 100000},\n",
        "             11: {0.5 : 10.34,\n",
        "                  0.25 : 13.7,\n",
        "                  0.1 : 17.27,\n",
        "                  0.05 : 19.68,\n",
        "                  0.0001 : 100000}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_y553Q3Dup_",
        "outputId": "348ee256-75c6-4e2e-a02a-85034bbe0799"
      },
      "source": [
        "#### Your code here ####\n",
        "from matplotlib.patches import Ellipse\n",
        "\n",
        "training_accuracy = []\n",
        "testing_accuracy = []\n",
        "tuples = []\n",
        "p_values = [1, 0.5, 0.25, 0.1, 0.05, 0.0001]\n",
        "for p_value in p_values:\n",
        "    tree = build_tree(X_train, impurity = best_impurity, gain_ratio = best_gain_ratio, chi = p_value)\n",
        "    training_accuracy.append(calc_accuracy(tree, X_train))\n",
        "    testing_accuracy.append(calc_accuracy(tree, X_test))\n",
        "    tree_depth = str(tree.tree_depth())\n",
        "    p = str(p_value)\n",
        "    str_tuple = p + \", \" + tree_depth \n",
        "    tuples.append(str_tuple)\n",
        "tuples.reverse()\n",
        "training_accuracy.reverse()\n",
        "testing_accuracy.reverse()\n",
        "best_value_chi = max(testing_accuracy)\n",
        "best_index_chi = np.argmax(testing_accuracy) + 1\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.plot(tuples, training_accuracy, marker='o')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('(p_value, depth)')\n",
        "plt.plot(tuples, testing_accuracy, marker='o')\n",
        "circle = Ellipse((best_index_chi, best_value_chi), width = 0.2, height = 2, color = 'red', fill = False)\n",
        "plt.gcf().gca().add_artist(circle)\n",
        "plt.legend(['training', 'testing'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x1c62a2d5f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqxNtpapDup_"
      },
      "source": [
        "Build the best 2 trees:\n",
        "1. tree_max_depth - the best tree according to max_depth pruning\n",
        "1. tree_chi - the best tree according to chi square pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh7y6ZUeDup_"
      },
      "source": [
        "#### Your code here ####\n",
        "tree_post_pruning = best_post_purning_tree\n",
        "tree_chi = build_tree(X_train, impurity = best_impurity, gain_ratio = best_gain_ratio, chi = p_values[len(p_values) - best_index_chi])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbmonj2JDuqA"
      },
      "source": [
        "## Number of Nodes\n",
        "\n",
        "Of the two trees above we will choose the one with fewer nodes. Complete the function counts_nodes and print the number of nodes in each tree. (5 points) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqb2f-CMDuqA",
        "outputId": "6bb08823-a264-456b-b1bf-75b336a73833"
      },
      "source": [
        "def count_nodes(node):\n",
        "    \"\"\"\n",
        "    Count the number of node in a given tree\n",
        " \n",
        "    Input:\n",
        "    - node: a node in the decision tree.\n",
        " \n",
        "    Output: the number of node in the tree.\n",
        "    \"\"\"\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    if(node.children_count() == 0):\n",
        "        return 1\n",
        "    nodes = 1\n",
        "    for child in node.children:\n",
        "        nodes = nodes + count_nodes(child[0])\n",
        "    return nodes\n",
        "\n",
        "node_num_dict = {}\n",
        "node_num_dict[tree_post_pruning] = count_nodes(tree_post_pruning)\n",
        "node_num_dict[tree_chi] = count_nodes(tree_chi)\n",
        "print(\"Post pruning number of nodes: \", node_num_dict[tree_post_pruning])\n",
        "print(\"Chi square pruning number of nodes: \", node_num_dict[tree_chi])\n",
        "chosen_tree = min(node_num_dict.keys(), key = (lambda k: node_num_dict[k]))\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Post pruning number of nodes:  274\n",
            "Chi square pruning number of nodes:  48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKxP9WzgDuqA"
      },
      "source": [
        "## Print the tree\n",
        "\n",
        "Complete the function `print_tree` and execute it on your chosen tree. Your tree should be visualized clearly. You can use the following example as a reference:\n",
        "```\n",
        "[ROOT, feature=X0],\n",
        "  [X0=a, feature=X2]\n",
        "    [X2=c, leaf]: [{1.0: 10}]\n",
        "    [X2=d, leaf]: [{0.0: 10}]\n",
        "  [X0=y, feature=X5], \n",
        "    [X5=a, leaf]: [{1.0: 5}]\n",
        "    [X5=s, leaf]: [{0.0: 10}]\n",
        "  [X0=e, leaf]: [{0.0: 25, 1.0: 50}]\n",
        "```\n",
        "In each brackets:\n",
        "* The first argument is the parent feature with the value that led to current node\n",
        "* The second argument is the selected feature of the current node\n",
        "* If the current node is a leaf, you need to print also the labels and their counts\n",
        "\n",
        "(5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqgXzdjEDuqB",
        "outputId": "b1ab8679-e22c-4272-a7c0-a74541d2e85e"
      },
      "source": [
        "# you can change the function signeture\n",
        "def print_tree(node, depth=0, parent_feature='ROOT', feature_val='ROOT'):\n",
        "    '''\n",
        "    prints the tree according to the example above\n",
        "\n",
        "    Input:\n",
        "    - node: a node in the decision tree\n",
        "\n",
        "    This function has no return value\n",
        "    '''\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    if (parent_feature == 'ROOT'):\n",
        "        print(\"[ROOT, feature=X{}],\".format(node.feature))\n",
        "    elif (node.is_leaf() == False):\n",
        "        print(\"{}[X{}={}, feature=X{}],\".format(print_indentation(depth), parent_feature, feature_val, node.feature))\n",
        "    elif (len(node.labels_counts) == 1):\n",
        "        print(\"{}[X{}={}, leaf]: [{{{}: {}}}]\".format(print_indentation(depth), parent_feature, feature_val, node.labels_counts[0][0], node.labels_counts[0][1]))\n",
        "        return\n",
        "    else:\n",
        "        print(\"{}[X{}={}, leaf]: [{{{}: {}, {}: {}}}]\".format(print_indentation(depth), parent_feature, feature_val, node.labels_counts[0][0], node.labels_counts[0][1], node.labels_counts[1][0], node.labels_counts[1][1]))\n",
        "        return\n",
        "    for child in node.children:\n",
        "        print_tree(child[0], depth + 1, node.feature, child[1])\n",
        "\n",
        "def print_indentation(depth): # Help function to print indentation according to the example\n",
        "    if (depth == 0):\n",
        "        return \"\"\n",
        "    else:\n",
        "        indent = \" \"\n",
        "        for i in range(0, depth - 1):\n",
        "            indent = indent + \" \"\n",
        "    return indent + indent\n",
        "\n",
        "print_tree(chosen_tree)\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ROOT, feature=X4],\n",
            "  [X4=a, leaf]: [{e: 273, p: 31}]\n",
            "  [X4=c, leaf]: [{e: 10, p: 137}]\n",
            "  [X4=f, feature=X10],\n",
            "    [X10=f, leaf]: [{e: 14, p: 91}]\n",
            "    [X10=k, leaf]: [{e: 134, p: 1037}]\n",
            "    [X10=s, leaf]: [{e: 22, p: 310}]\n",
            "  [X4=l, feature=X1],\n",
            "    [X1=f, leaf]: [{e: 19, p: 1}]\n",
            "    [X1=s, leaf]: [{e: 94, p: 16}]\n",
            "    [X1=y, leaf]: [{e: 159, p: 10}]\n",
            "  [X4=m, leaf]: [{e: 2, p: 25}]\n",
            "  [X4=n, feature=X18],\n",
            "    [X18=b, leaf]: [{e: 34, p: 2}]\n",
            "    [X18=h, feature=X2],\n",
            "      [X2=r, leaf]: [{e: 9, p: 4}]\n",
            "      [X2=u, leaf]: [{e: 14}]\n",
            "      [X2=w, leaf]: [{e: 12, p: 1}]\n",
            "    [X18=k, leaf]: [{e: 875, p: 96}]\n",
            "    [X18=n, leaf]: [{e: 916, p: 110}]\n",
            "    [X18=o, feature=X19],\n",
            "      [X19=c, leaf]: [{e: 12, p: 4}]\n",
            "      [X19=v, leaf]: [{e: 16}]\n",
            "    [X18=r, leaf]: [{e: 6, p: 46}]\n",
            "    [X18=w, feature=X20],\n",
            "      [X20=d, feature=X7],\n",
            "        [X7=b, leaf]: [{e: 6, p: 2}]\n",
            "        [X7=n, leaf]: [{p: 25}]\n",
            "      [X20=g, leaf]: [{e: 204, p: 19}]\n",
            "      [X20=l, feature=X2],\n",
            "        [X2=c, leaf]: [{e: 19, p: 1}]\n",
            "        [X2=n, leaf]: [{e: 15, p: 4}]\n",
            "        [X2=w, leaf]: [{p: 8}]\n",
            "        [X2=y, leaf]: [{p: 7}]\n",
            "      [X20=p, leaf]: [{e: 29, p: 1}]\n",
            "      [X20=w, feature=X13],\n",
            "        [X13=e, leaf]: [{e: 62, p: 9}]\n",
            "        [X13=w, leaf]: [{e: 68, p: 2}]\n",
            "    [X18=y, leaf]: [{e: 35, p: 3}]\n",
            "  [X4=p, feature=X0],\n",
            "    [X0=f, leaf]: [{e: 7, p: 86}]\n",
            "    [X0=x, leaf]: [{e: 1, p: 89}]\n",
            "  [X4=s, feature=X13],\n",
            "    [X13=p, leaf]: [{e: 12, p: 190}]\n",
            "    [X13=w, feature=X12],\n",
            "      [X12=p, leaf]: [{e: 18, p: 88}]\n",
            "      [X12=w, leaf]: [{e: 8, p: 102}]\n",
            "  [X4=y, leaf]: [{e: 49, p: 382}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
